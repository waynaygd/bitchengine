{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ecc4d14",
      "metadata": {
        "id": "2ecc4d14"
      },
      "source": [
        "# Задание 1. Старт. Загрузка и осмотр данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tCApZcOxBA2S",
      "metadata": {
        "id": "tCApZcOxBA2S"
      },
      "source": [
        "## Шаг 0. Настройка среды выполнения\n",
        "Если вы выполняете задание на локальной машине, перед выполнением задания создайте виртуальную среду, активируйте ее и скачайте библиотеки `pandas`, `numpy`, `matplotlib` и `seaborn`.  \n",
        "\n",
        "Если вы выполняете задание в colab или kaggle, активируйте среду выполнения."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "atS9Iazi-jdB",
      "metadata": {
        "id": "atS9Iazi-jdB"
      },
      "source": [
        "## Шаг 1. Определение номера варианта и скачивание датасета\n",
        "Перейдите в Google Таблицу со списком студентов. Найдите свое ФИО в списке и запомните соответствующий порядковый номер (поле № п/п) в первом столбце. Заполните его в ячейке ниже и выполните ячейку. Если вы не можете найти себя в списке, обратитесь к своему преподавателю практики.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kTXjKrh2_KWa",
      "metadata": {
        "id": "kTXjKrh2_KWa"
      },
      "outputs": [],
      "source": [
        "Student_ID = 17"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_bBgWLMo_PWZ",
      "metadata": {
        "id": "_bBgWLMo_PWZ"
      },
      "source": [
        "Теперь выполните следующую ячейку. Она вычислит номер задания и выведет его."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "07bda900",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07bda900",
        "outputId": "e3bc079a-e131-44ce-9a2b-b0f7d06a7b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет 'Video Game Sales with Ratings' доступен по следующей ссылке: https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings\n"
          ]
        }
      ],
      "source": [
        "datasets = [\n",
        "    ('US Air Carrier market in 2019','https://raw.githubusercontent.com/markpolyak/datasets/refs/heads/main/data/aircarrier_market_us_2019.zip'),\n",
        "    ('Video Game Sales with Ratings', 'https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings'),\n",
        "    ('Medical Cost Personal Dataset', 'https://www.kaggle.com/datasets/mirichoi0218/insurance'),\n",
        "    ('Netflix Movies and TV Shows', 'https://www.kaggle.com/datasets/shivamb/netflix-shows')\n",
        "]\n",
        "\n",
        "dataset_id = None if Student_ID is None else Student_ID % len(datasets)\n",
        "if dataset_id is None:\n",
        "    print(\"ОШИБКА! Не указан порядковый номер студента в списке группы.\")\n",
        "else:\n",
        "    print(f\"Датасет '{datasets[dataset_id][0]}' доступен по ссылке: {datasets[dataset_id][1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Jx8Vc_AMAE_Z",
      "metadata": {
        "id": "Jx8Vc_AMAE_Z"
      },
      "source": [
        "**Скачайте датасет** Если вам дана ссылка на файл (.csv, .zip, .tsv и так далее), скачайте его с помощью команды `!wget <dataset_url>` или вызова утилиты `curl ...`, где `<dataset_url>` необходимо заменить на ссылку на датасет, появившуюся после выполнения предыдущей ячейки. При необходимости разархивируйте датасет, используя команды `!unzip`, `!tar` и др.\n",
        "\n",
        "Если вам дана ссылка на kaggle.com, перейдите по ней и скачайте датасет с помощью кнопки download. В раскрывающемся списке \"Download via\" выберите cUrl и скопируйте подготовленную команду bash в ячейку с кодом ниже. При возникновении трудностей обратитесь к вашему преподавателю-практику.\n",
        "\n",
        "**Примечание**: в Jupyter-ноутбуке можно использовать любые команды командного интерпретатора bash. Для этого необходимо поставить в ячейке с кодом восклицательный знак !, после которого записать команду bash со всеми необходимыми аргументами. Результат выполнения этой команды bash будет возвращен в Jupyter и его можно использовать в коде на Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "nJEXZqL8AeUS",
      "metadata": {
        "id": "nJEXZqL8AeUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327e2608-a5d5-4a61-f732-c5c5bc14abe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'video-game-sales-with-ratings' dataset.\n",
            "Path to dataset files: /kaggle/input/video-game-sales-with-ratings\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rush4ratio/video-game-sales-with-ratings\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WCrz2UawBhhy",
      "metadata": {
        "id": "WCrz2UawBhhy"
      },
      "source": [
        "## Шаг 2. Загрузка данных\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fwKbXSJxBt-i",
      "metadata": {
        "id": "fwKbXSJxBt-i"
      },
      "source": [
        "Загрузите датасет в `pandas.DataFrame`, сохраните его в переменной `df`. Проинспектируйте датасет, используя `df.head()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "TE8LZRzMAgaK",
      "metadata": {
        "id": "TE8LZRzMAgaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "105e657e-98a6-4d97-c2dd-1864abf5587c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/rush4ratio/video-game-sales-with-ratings/versions/2/Video_Games_Sales_as_at_22_Dec_2016.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-47089673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/.cache/kagglehub/datasets/rush4ratio/video-game-sales-with-ratings/versions/2/Video_Games_Sales_as_at_22_Dec_2016.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/rush4ratio/video-game-sales-with-ratings/versions/2/Video_Games_Sales_as_at_22_Dec_2016.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/rush4ratio/video-game-sales-with-ratings/versions/2/Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "De-1QoNlCqDC",
      "metadata": {
        "id": "De-1QoNlCqDC"
      },
      "source": [
        "Сконвертируйте названия столбцов в нижний регистр, после этого создайте переменную `columns` и сохраните в нее список столбцов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xGkNBaAeC52K",
      "metadata": {
        "id": "xGkNBaAeC52K"
      },
      "outputs": [],
      "source": [
        "df.columns = df.columns.str.lower()\n",
        "\n",
        "columns = df.columns.tolist()\n",
        "\n",
        "print(columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d159owP3HWGa",
      "metadata": {
        "id": "d159owP3HWGa"
      },
      "source": [
        "При желании, выведите информацию о датафрейме с помощью функции `.info()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5FS92IkKHU7",
      "metadata": {
        "id": "Y5FS92IkKHU7"
      },
      "outputs": [],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_KHbQsg2D7yC",
      "metadata": {
        "id": "_KHbQsg2D7yC"
      },
      "source": [
        "## Шаг 3. Анализ датафрейма\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1-E3MS7EC_a",
      "metadata": {
        "id": "e1-E3MS7EC_a"
      },
      "source": [
        "Проверьте, есть ли в данном датасете пропущенные значения? Удалите из датафрейма **объекты** с пропущенными значениями.\n",
        "\n",
        "**ВАЖНО**: не перезаписывайте исходную переменную `df`, вместо этого сохраните новый датафрейм в переменную `df_dropna`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x1cUR78KEBR7",
      "metadata": {
        "id": "x1cUR78KEBR7"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())\n",
        "\n",
        "print()\n",
        "df_dropna = df.dropna()\n",
        "\n",
        "print(df_dropna.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p0xE8wnUGumL",
      "metadata": {
        "id": "p0xE8wnUGumL"
      },
      "source": [
        "Сгенерируйте статистики по вашему датасету. Подсказка: для этого у датафрейма есть встренная функция `.describe()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kSG9tLDiG_Or",
      "metadata": {
        "id": "kSG9tLDiG_Or"
      },
      "outputs": [],
      "source": [
        "print(df_dropna.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ogPi6lJFFQRP",
      "metadata": {
        "id": "ogPi6lJFFQRP"
      },
      "source": [
        "### Дополнительное задание *. Заполните пропуски в датасете\n",
        "\n",
        "Для того, чтобы заполнить пропуски, используйте моды для соответствующего категориального признака и медианное значение для числового, если такие есть. Например, если в столбце `A` есть несколько пропусков, найдите моду столбца `A_dropna` (очищенного от пропусков) и заполните ею все остальные пропуски.\n",
        "\n",
        "**ВАЖНО**: Дополнительное задание не является обязательным к выполнению, но позволяет получить дополнительные баллы по курсу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FDkvusnpGfwK",
      "metadata": {
        "id": "FDkvusnpGfwK"
      },
      "outputs": [],
      "source": [
        "### BEGIN YOUR CODE\n",
        "\n",
        "df_fillna = ...\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca066559",
      "metadata": {
        "id": "ca066559"
      },
      "source": [
        "# Задание 2. Работа с числовыми признаками"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "msfaJ8mSNIPU",
      "metadata": {
        "id": "msfaJ8mSNIPU"
      },
      "source": [
        "## Шаг 1. Отбор числовых признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nhpPbEB3KKCj",
      "metadata": {
        "id": "nhpPbEB3KKCj"
      },
      "source": [
        "Определите числовые признаки датасета. Запишите их названия в список `numeric_features`. После этого, отделите от датафрейма часть со всеми числовыми признаками.\n",
        "\n",
        "**ВАЖНО**: Не перезаписывайте `df_dropna`, вместо этого запишите полученный датафрейм в переменную `df_numeric`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18eae7f0",
      "metadata": {
        "id": "18eae7f0"
      },
      "outputs": [],
      "source": [
        "numeric_features = df_dropna.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "print(numeric_features)\n",
        "\n",
        "df_numeric = df_dropna[numeric_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r7TKiQ9ONNXL",
      "metadata": {
        "id": "r7TKiQ9ONNXL"
      },
      "source": [
        "## Шаг 2. Визуализация распределений"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I-gPvFN2LufL",
      "metadata": {
        "id": "I-gPvFN2LufL"
      },
      "source": [
        "Для каждого числового признака визуализируйте его распределение, используя гистограммы. Для наглядности, поместите название признака в заголовок гистограммы.\n",
        "\n",
        "Подсказка: вы можете использовать `plt.subplots` для размещения нескольких визуализаций на одной фигуре."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rv6hwVqEL-dc",
      "metadata": {
        "id": "rv6hwVqEL-dc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_features = len(numeric_features)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_features, ncols=1, figsize=(8, 4 * n_features))\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, col in enumerate(numeric_features):\n",
        "    axes[i].hist(df_numeric[col], bins=32, color=\"red\", edgecolor=\"black\")\n",
        "    axes[i].set_title(col)\n",
        "    axes[i].set_xlabel(\"Значения\")\n",
        "    axes[i].set_ylabel(\"Частота\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DQAEemFaNZ88",
      "metadata": {
        "id": "DQAEemFaNZ88"
      },
      "source": [
        "## Шаг 3. Поиск корреляции между числовыми признаками"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-JDVsLsGPKcE",
      "metadata": {
        "id": "-JDVsLsGPKcE"
      },
      "source": [
        "Вычислите корреляции по Пирсону и по Спирмену между всеми парами числовых признаков. Подумайте, в чем между ними разница?\n",
        "\n",
        "Подсказка: вы можете вычислять корреляции вручную, это будет даже похвально. А можете использовать встроенный метод `df_numeric.corr(...)`. Рекомендуется посмотреть документацию перед использованием: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xZmd0XUeQ-Xs",
      "metadata": {
        "id": "xZmd0XUeQ-Xs"
      },
      "outputs": [],
      "source": [
        "corr_pearson = df_numeric.corr(method=\"pearson\")\n",
        "corr_spearman = df_numeric.corr(method=\"spearman\")\n",
        "\n",
        "print(\"Корреляция по Пирсону:\")\n",
        "print(corr_pearson)\n",
        "\n",
        "print(\"\\nКорреляция по Спирмену:\")\n",
        "print(corr_spearman)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66IDwDLXRV5N",
      "metadata": {
        "id": "66IDwDLXRV5N"
      },
      "source": [
        "Для корреляций признаков по Пирсону постройте тепловую карту от -1 до 1, с центром в 0. Запишите название признака для каждой строки и каждого столбца.\n",
        "\n",
        "Подсказка: вы можете использовать `seaborn.heatmap()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V1-BNd4dRtVM",
      "metadata": {
        "id": "V1-BNd4dRtVM"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### BEGIN YOUR CODE\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_pearson, annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1, center=0)\n",
        "\n",
        "plt.title(\"Корреляция признаков по Пирсону\")\n",
        "plt.show()\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GY2vod-GSA58",
      "metadata": {
        "id": "GY2vod-GSA58"
      },
      "source": [
        "Аналогично, для корреляций по Спирмену постройте тепловую карту от -1 до 1, с центром в 0. Запишите название признака для каждой строки и каждого столбца.\n",
        "\n",
        "Оцените результаты. Сравните тепловую карту для корреляций по Пирсону и по Спирмену."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tcp9eAfXSAll",
      "metadata": {
        "id": "tcp9eAfXSAll"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### BEGIN YOUR CODE\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_spearman, annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1, center=0)\n",
        "\n",
        "plt.title(\"Корреляция признаков по Спирмену\")\n",
        "plt.show()\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UyMS6QrnOAA8",
      "metadata": {
        "id": "UyMS6QrnOAA8"
      },
      "source": [
        "## Шаг 4. Вычисление статистик"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_DDLOX_EODXj",
      "metadata": {
        "id": "_DDLOX_EODXj"
      },
      "source": [
        "Для каждого числового признака вычислите среднее, медиану и стандартное отклонение.\n",
        "\n",
        "Результаты запишите в соответствующие словари `means`, `medians` и `stds`, в которых ключ (`key`) - название признака (как он записан в датафрейме), значение (`value`) - статистика."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NMFgho-fO2tM",
      "metadata": {
        "id": "NMFgho-fO2tM"
      },
      "outputs": [],
      "source": [
        "### BEGIN YOUR CODE\n",
        "means = {}\n",
        "medians = {}\n",
        "stds = {}\n",
        "\n",
        "for col in numeric_features:\n",
        "    means[col] = df_numeric[col].mean()\n",
        "    medians[col] = df_numeric[col].median()\n",
        "    stds[col] = df_numeric[col].std()\n",
        "\n",
        "print(\"Средние значения:\", means)\n",
        "print(\"Медианы:\", medians)\n",
        "print(\"Стандартные отклонения:\", stds)\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mrk_MZxYS97E",
      "metadata": {
        "id": "mrk_MZxYS97E"
      },
      "source": [
        "## Шаг 5. Стандартизация признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fXfIxwX_TmVt",
      "metadata": {
        "id": "fXfIxwX_TmVt"
      },
      "source": [
        "Выполните стандартизацию для каждого числового признака:\n",
        "\n",
        "$$\n",
        "z = \\dfrac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "где $\\mu$ - среднее по признаку, $\\sigma$ - стандартное отклонение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EuoFEBX1UIJ9",
      "metadata": {
        "id": "EuoFEBX1UIJ9"
      },
      "outputs": [],
      "source": [
        "### BEGIN YOUR CODE\n",
        "df_standart = (df_numeric - df_numeric.mean()) / df_numeric.std()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_features = len(numeric_features)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_features, ncols=1, figsize=(8, 4 * n_features))\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, col in enumerate(numeric_features):\n",
        "    axes[i].hist(df_standart[col], bins=32, color=\"blue\", edgecolor=\"black\")\n",
        "    axes[i].set_title(f\"{col} (стандартизированный)\")\n",
        "    axes[i].set_xlabel(\"Значения (z-score)\")\n",
        "    axes[i].set_ylabel(\"Частота\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PuqOf8W3URt0",
      "metadata": {
        "id": "PuqOf8W3URt0"
      },
      "source": [
        "Подсказка: используйте статистики из предыдущего задания"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2H66_Kw2Uqbk",
      "metadata": {
        "id": "2H66_Kw2Uqbk"
      },
      "source": [
        "Повторите шаг 2 этого задания для полученного датафрейма: визуализируйте. Сравните с результатом, полученным ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10570b7e",
      "metadata": {
        "id": "10570b7e"
      },
      "source": [
        "# Задание 3. Работа с категориальными признаками"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hqDl1dYDVK0t",
      "metadata": {
        "id": "hqDl1dYDVK0t"
      },
      "source": [
        "## Шаг 1. Отбор категориальных признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QHhnEZhYVyid",
      "metadata": {
        "id": "QHhnEZhYVyid"
      },
      "source": [
        "Определите категориальные признаки датасета. Запишите их названия в список `cat_features`. После этого, отделите от датафрейма часть со всеми категориальными признаками.\n",
        "\n",
        "**ВАЖНО**: Не перезаписывайте `df_dropna`, вместо этого запишите полученный датафрейм в переменную `df_cat`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0f6fe8",
      "metadata": {
        "id": "aa0f6fe8",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "cat_features = df_dropna.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "df_cat = df_dropna[cat_features]\n",
        "\n",
        "print(\"Категориальные признаки:\", cat_features)\n",
        "print(df_cat.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wer2qw7qVVFd",
      "metadata": {
        "id": "wer2qw7qVVFd"
      },
      "source": [
        "## Шаг 2. Визуализация распределений категориальных признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z7ysyU-tWLHV",
      "metadata": {
        "id": "z7ysyU-tWLHV"
      },
      "source": [
        "Для каждого категориального признака визуализируйте его распределение. Используйте круговую диаграмму (`plt.pie`). Для каждой диаграммы выведите легенду (с указанием категории) и запишите в заголовок имя признака."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fQkFXo7-Vcwl",
      "metadata": {
        "id": "fQkFXo7-Vcwl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_features = len(cat_features)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_features, ncols=1, figsize=(500, 6 * n_features))\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for col in cat_features:\n",
        "    counts = df_cat[col].value_counts()\n",
        "\n",
        "    if len(counts) > 25:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        counts.head(25).plot(kind=\"bar\")\n",
        "        plt.title(f\"Распределение (топ-25): {col}\")\n",
        "        plt.xlabel(\"Категории\")\n",
        "        plt.ylabel(\"Количество\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.figure(figsize=(25, 6))\n",
        "        plt.pie(counts, labels=counts.index, autopct=\"%1.1f%%\", startangle=90)\n",
        "        plt.title(f\"Распределение: {col}\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G0YkQkfvVdEl",
      "metadata": {
        "id": "G0YkQkfvVdEl"
      },
      "source": [
        "## Шаг 3. One-hot-encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lMzc-99OYS5F",
      "metadata": {
        "id": "lMzc-99OYS5F"
      },
      "source": [
        "Примените one-hot кодирование для ваших категориальных признаков.\n",
        "Подсказка: используйте `pandas.get_dummies(...)`.\n",
        "\n",
        "**ВАЖНО**: не перезаписывайте `df_cat`, запишите результат в переменную `df_ohe`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0HWkKaroVhS9",
      "metadata": {
        "id": "0HWkKaroVhS9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_ohe = pd.get_dummies(df_cat, drop_first=False)\n",
        "\n",
        "print(df_ohe.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad332a3",
      "metadata": {
        "id": "3ad332a3"
      },
      "source": [
        "# Задание 4. Поиск выбросов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i6SyuCn4aKll",
      "metadata": {
        "id": "i6SyuCn4aKll"
      },
      "source": [
        "В этом задании будем использовать полученные ранее датафреймы `df_standart` и `df_ohe`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q85N15f7a4gW",
      "metadata": {
        "id": "q85N15f7a4gW"
      },
      "source": [
        "Очистите данные от выбросов, используя метод $3 \\sigma$ и `df_standart`. Поскольку числовые данные уже стандартизированы, выбросом будем считать объект $|x| > 3$ (длина объекта больше 3).\n",
        "\n",
        "Вам необходимо найти выбросы среди `df_standart`, удалить их, если они есть, и удалить соответствующие объекты среди `df_ohe`. Объедините датафреймы и запишите результат в переменную `df_filtered`.\n",
        "\n",
        "**ВАЖНО**: не перезаписывайте переменные `df_standart` и `df_ohe`. Для промежуточных результатов создавайте другие переменные, например `df_standart_f` и `df_ohe_f`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_7ZmhU_JdJr3",
      "metadata": {
        "id": "_7ZmhU_JdJr3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "outliers_mask = (df_standart.abs() > 3).any(axis=1)\n",
        "keep_mask = ~outliers_mask\n",
        "\n",
        "df_standart_f = df_standart[keep_mask].copy()\n",
        "\n",
        "df_ohe_f = df_ohe.loc[df_standart_f.index].copy()\n",
        "\n",
        "df_filtered = pd.concat([df_standart_f, df_ohe_f], axis=1)\n",
        "\n",
        "print(f\"Было строк: {len(df_standart)}\")\n",
        "print(f\"Выбросов по 3σ: {outliers_mask.sum()}\")\n",
        "print(f\"Осталось строк: {len(df_filtered)}\")\n",
        "print(df_filtered.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2L0acaEfQZX",
      "metadata": {
        "id": "a2L0acaEfQZX"
      },
      "source": [
        "### Дополнительное задание **.  Расстояния от центроида кластера\n",
        "**ВАЖНО**: Дополнительное задание не является обязательным к выполнению, но позволяет получить дополнительные баллы по курсу.\n",
        "\n",
        "В рамках этого дополнительного задания попробуйте найти выбросы через расстояния до центроидов кластеров. Для этого выполните кластеризацию датасета.\n",
        "Затем, чтобы найти выбросы, постройте для каждого кластера распределение расстояний до центроида. Выбросы отсекайте по перцентилям (значения выберите на ваше усмотрение).\n",
        "\n",
        "Замечание: для этого задания вы можете использовать библиотку scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c720ca24",
      "metadata": {
        "id": "c720ca24"
      },
      "outputs": [],
      "source": [
        "### BEGIN YOUR CODE\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}